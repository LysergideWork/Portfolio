# Проект 16: Data Science кейс с GPN-CUP 2023

### *Выполнил*:
Мостовой Роман Павлович

### *Направление*: 
Машинное обучение, Анализ времянных рядов

### *Задача*: 
Нам предстоит составить расписание цен на 90 дней для 5-ти городов и 3-х продуктов сети, с целью получения максимальной прибыли, относительно предоставленной постоянной цены.

### *Описание*:
Сеть "Главное Пристанище Надежды" занимается продажей товаров для здоровья в 5-ти городах.

### *Инструменты*: 
Python, Pandas, Re, Phi_K, Seaborn, NumPy, Time, Category_encoders, Scikitplot, SHAP, Statsmodels, Matplotlib, Sklearn, Imblearn, LightGBM, CatBoost, Pipeline, SMOTE, SVM

### *Вывод*:
Мы загрузили 4 таблицы, из которых состоят данные:
- `transaction_df.parquet` — данные о транзакциях;
- `df_competitors.parquet` — данные о ценах конкурентов;
- `weather_df.parquet` — данные о погоде;
- `df_cost.parquet` — данные о себестоимости.

Оценили каждую из них и обнаружили следующее:
- начало среза: 2216-01-02;
- окончание среза: 2218-09-27;
- cтолбец `place` имеет 432 пропуска;
- столбец `amount` имеет нормальное распределение значений от -0.5 до 1.99, при этом отрицательные значения - это аномалии или ошибки;
- столбец `price` имеет много отрицательных выбросов;
- в столбце `cost` может быть недостаточно данных.

Было решено объединять все таблицы в одну с индексом по столбцу `date`. Для этого пришлось обработать все аномалии и пропуски. Пропуски в столбце `place` мы удалили, т.к. их замена заняла бы слишком много времени. Отрицательные значения в столбце `price` мы заменили на наиболее вероятные. При замене мы воспользовались правилом, что цена может не может меняться в течении 3-х дней, а наиболее вероятная цена - это та, которая встречается больше всего раз в одной и той же комбинации даты, места и товара. Аномалию в столбце `amount` было решено исправить сдвигом всех значений на 0.5.  
Далее мы сгруппировали ДатаФрейм `df_transactions` так, чтобы для каждой уникальной комбинации даты, продукта и места мы получили сумму значения столбца `amount`.  
Мы выяснили, что у столбцов `hot`, `rain` и `snow` в ДатаФрейме `df_weather` всего 4 уникальных комбинации, а это значит, что каждый столбец - это булева переменная. Мы переписали эти 3 столбца в 1 категориальный столбец `weather`, который будет принимать 4 возможных варианта ответа: `hot`, `rain`, `snow` и `clear`.  
В ДатаФрейме `df_competitors` мы выделили цены каждого конкурента в отдельный столбец и провели группировку по дате, товару и месту.  
Теперь все таблицы приведены к нужному виду и их можно объединять.  
Пропуски в столбце `cost` мы заполнили при помощи интерполяции, а в столбцах с ценами конкурентов при помощи интерполяции и метода `bfill`.  
При графическом анализе себестоимости, обратили внимание на высокие амплетуды колебаний.  
Создали дополнительные признаки `income` и `spread`:
- `spread` - наценка или маржа, это разница между `price` и `cost`; 
- `income` - чистая прибыль, это произведение `spread` и `amount`.  

Графически оценили чистую прибыль (`income`), отметили характерные для `cost` амплетуды колебания.  
Оценили стационарность с помощью теста ADF (расширенный тест Дики – Фуллера).  

Для обучения модели и прогнозирования цены, мы выбрали библиотеку Prophet. подготовили датасет, обучили модель на заданных параметрах, сделали предсказание и визуализировали результат. Определили точность модели с помощью среднеквадратичной ошибки (RMSE). Сравнили получившийся результат с предложенной Baseline моделью. На графике визуально определили, что цены, предсказанные с помощью библиотеки Prophet, выше постоянной цены из Baseline.  
С помощью функции, мы составили предсказание цены для каждого из 3-х продуктов в 5-ти городах на 90 дней вперед. И выгрузили это предсказание в файл `df_price_predicted.parquet`
