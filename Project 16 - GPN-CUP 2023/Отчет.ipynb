{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7762edb1",
   "metadata": {},
   "source": [
    "Привет! Меня зовут Мостовой Роман, я начинающий Data Scientist, и это мой отчет по проделанной работе над кейсом GPN-CUP 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5f2ce",
   "metadata": {},
   "source": [
    "Хочу отдельно отметить стиль подачи задания, видно, что приложено много сил и фантазии. Спасибо за предоставленную возможность опробовать свои силы!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963708c",
   "metadata": {},
   "source": [
    "Итак, я начал с того, что загрузил 4 таблицы, из которых состоят данные:\n",
    "- `transaction_df.parquet` — данные о транзакциях;\n",
    "- `df_competitors.parquet` — данные о ценах конкурентов;\n",
    "- `weather_df.parquet` — данные о погоде;\n",
    "- `df_cost.parquet` — данные о себестоимости.\n",
    "\n",
    "Оценил каждую из них и обнаружил следующее:\n",
    "- начало среза: 2216-01-02;\n",
    "- окончание среза: 2218-09-27;\n",
    "- cтолбец `place` имеет 432 пропуска;\n",
    "- столбец `amount` имеет нормальное распределение значений от -0.5 до 1.99, при этом отрицательные значения - это аномалии или ошибки;\n",
    "- столбец `price` имеет много отрицательных выбросов;\n",
    "- в столбце `cost` может быть недостаточно данных.\n",
    "\n",
    "Было решено объединять все таблицы в одну с индексом по столбцу `date`. Для этого пришлось обработать все аномалии и пропуски. Пропуски в столбце `place` удалил, т.к. их замена заняла бы слишком много времени. Отрицательные значения в столбце `price` заменил на наиболее вероятные. При замене воспользовался правилом, что цена не может меняться в течении 3-х дней, а наиболее вероятная цена получается та, которая встречается больше всего раз в одной и той же комбинации даты, места и товара. Аномалию в столбце `amount` было решено исправить сдвигом всех значений на 0.5. *Применяя эти решения я старался сохранить максимальное количество данных. Все аномалии можно было удалить. Еще как вариант в столбце `amount`, все отрицательные значения можно было заменить на положительные. Если рассмотреть все возможные варианты замен, то у нас бы могло получится 6 разных датасетов.*  \n",
    "Далее я сгруппировал ДатаФрейм `df_transactions` так, чтобы для каждой уникальной комбинации даты, продукта и места мы получили сумму значения столбца `amount`. *Тут я хотел добится чего-то вроде мультииндекса (дата, место, продукт), чтобы в дальнейшем было удобнее работь с данными.*  \n",
    "Я выяснил, что у столбцов `hot`, `rain` и `snow` в ДатаФрейме `df_weather` всего 4 уникальных комбинации, а это значит, что каждый столбец - это булева переменная. Я переписал эти 3 столбца в 1 категориальный столбец `weather`, который будет принимать 4 возможных варианта ответа: `hot`, `rain`, `snow` и `clear`.  \n",
    "В ДатаФрейме `df_competitors` выделил цены каждого конкурента в отдельный столбец и провели группировку по дате, товару и месту.  \n",
    "Теперь все таблицы приведены к нужному виду и их можно объединять.  \n",
    "Пропуски в столбце `cost` я заполнил при помощи интерполяции, а в столбцах с ценами конкурентов при помощи интерполяции и метода `bfill`. *Я пытался искать разные варианты как это сделать, но пропусков было настолько много, что я не смог придумать ничего лучше.*  \n",
    "При графическом анализе себестоимости, обратили внимание на высокие амплетуды колебаний. *У меня есть подозрения на аномалии значений в столбце `cost`, но сейчас мне не хватает опыта, чтобы правильно их определить.*  \n",
    "Создали дополнительные признаки `income` и `spread`:\n",
    "- `spread` - наценка или маржа, это разница между `price` и `cost`; \n",
    "- `income` - чистая прибыль, это произведение `spread` и `amount`.  \n",
    "\n",
    "Графически оценили чистую прибыль (`income`), отметили характерные для `cost` амплетуды колебания.  \n",
    "Оценили стационарность с помощью теста ADF (расширенный тест Дики – Фуллера).  \n",
    "\n",
    "Для обучения модели и прогнозирования цены, мы выбрали библиотеку Prophet. подготовили датасет, обучили модель на заданных параметрах, сделали предсказание и визуализировали результат. Определили точность модели с помощью среднеквадратичной ошибки (RMSE). Сравнили получившийся результат с предложенной Baseline моделью. На графике визуально определили, что цены, предсказанные с помощью библиотеки Prophet, выше постоянной цены из Baseline.  \n",
    "С помощью функции, мы составили предсказание цены для каждого из 3-х продуктов в 5-ти городах на 90 дней вперед. И выгрузили это предсказание в файл `df_price_predicted.parquet`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057ecb9",
   "metadata": {},
   "source": [
    "Увы, из-за болезни, мне не хватило времени, чтобы закончить эту работу..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1a4ed",
   "metadata": {},
   "source": [
    "Далее, я опишу то, на что мне не хватило времени и что я обызательно хочу доделать:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53211689",
   "metadata": {},
   "source": [
    "На данный момент предсказания `price`, я считаю, недостаточно для определения максимальной прибыли. Необходимо предсказать на 90 дней вперед цены каждого из конкурентов, возможно, создать еще один столбец со средней ценой конкурентов (не уверен, что как признак для обучения модели, это будет очень полезно, но стоит попробовать). А так же необходимо составить предсказание погоды (`weather`), себестоимости (`cost`) и объема продаж(`amount`).  \n",
    "Еще у меня есть гипотеза, что если `cost` преобразовать с помощью скользящего среднего, то это не должно сильно отразиться на прибыли, зато должно улучшить точность предсказания модели.  \n",
    "Итак, имея предсказания всех признаков на 90 дней вперед, можно лучше обучить модель и составить более точное предсказание по ценам. Я понимаю, что в каждом предсказании каждого признака будет содержаться какая-то ошибка и, чем больше у меня будет этих признаков, тем сильнее эта ошибка будет накапливаться. Этот аспект меня беспокоит.  \n",
    "Необходимо проанализировать при каких условиях были получины максимальные чистые прибыли и постараться обучить этому модель. Альтернативная гипотеза у меня следующая: возможно, стоит предсказывать именно максимальную чистую прибыль, а уже потом имея предсказания объемов продаж и себестоимости, вычислять цены.  \n",
    "Prophet - это хорошая универсальная библиотека для первичного анализа. Я же хочу оценить точность разных моделей: Decision Tree, Random Forest, LightGBM, CatBoost, нейросеть в несколько слоев. Но на графике цены хорошо читается линейность, поэтому, мне кажется, что линейные модели будут наиболее эффективны, например, Linear Regression или SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ded28",
   "metadata": {},
   "source": [
    "Оценю точность всех моделей, выберу одну и постараюсь на ней составить более точный прогноз цены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab9257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
