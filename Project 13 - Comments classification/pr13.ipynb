{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импортируем-библиотеки\" data-toc-modified-id=\"Импортируем-библиотеки-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импортируем библиотеки</a></span></li><li><span><a href=\"#Загружаем-и-изучаем-данные\" data-toc-modified-id=\"Загружаем-и-изучаем-данные-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Загружаем и изучаем данные</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression-с-взвешиванием-классов\" data-toc-modified-id=\"Logistic-Regression-с-взвешиванием-классов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Logistic Regression с взвешиванием классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Преобразование-текста-с-помощью-CountVectorizer\" data-toc-modified-id=\"Преобразование-текста-с-помощью-CountVectorizer-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Преобразование текста с помощью CountVectorizer</a></span></li><li><span><a href=\"#Преобразование-текста-с-помощью-TfidfVectorizer\" data-toc-modified-id=\"Преобразование-текста-с-помощью-TfidfVectorizer-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Преобразование текста с помощью TfidfVectorizer</a></span></li><li><span><a href=\"#Преобразование-текста-с-помощью-HashingVectorizer\" data-toc-modified-id=\"Преобразование-текста-с-помощью-HashingVectorizer-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Преобразование текста с помощью HashingVectorizer</a></span></li></ul></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LightGBM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Преобразование-текста-с-помощью-CountVectorizer\" data-toc-modified-id=\"Преобразование-текста-с-помощью-CountVectorizer-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Преобразование текста с помощью CountVectorizer</a></span></li><li><span><a href=\"#Преобразование-текста-с-помощью-TfidfVectorizer\" data-toc-modified-id=\"Преобразование-текста-с-помощью-TfidfVectorizer-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Преобразование текста с помощью TfidfVectorizer</a></span></li><li><span><a href=\"#Преобразование-текста-с-помощью-HashingVectorizer\" data-toc-modified-id=\"Преобразование-текста-с-помощью-HashingVectorizer-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Преобразование текста с помощью HashingVectorizer</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Проверка-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-на-тестовой-выборке-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Проверка на тестовой выборке</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам необходимо создать инструмент для интернет-магазина «Викишоп», который будет искать токсичные комментарии и отправлять их на модерацию. Для этого нужно обучить модель классифицировать комментарии на позитивные и негативные. Точность метрики качества F1 должна быть не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (8.1.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 46.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (63.4.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lysergide\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS = 12345\n",
    "KFOLD = KFold(n_splits = 5, random_state = RS, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем и изучаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "106294    1\n",
       "106287    1\n",
       "106288    1\n",
       "106289    1\n",
       "         ..\n",
       "53159     1\n",
       "53160     1\n",
       "53161     1\n",
       "53162     1\n",
       "159450    1\n",
       "Name: Unnamed: 0, Length: 159292, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[df['text'].str.contains(r\"\\b'\")].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный датасет состоит из 159292 строк и 3-х столбцов:\n",
    " - Unnamed: 0 - отражает порядковый номер комментария, для исследования не несет никакой ценности, мы его удалили.\n",
    " - text - это сам комментарий, сожержит текстовое сообщение, с которым нам предстоит работать.\n",
    " - toxic - это наш целевой признак, он отражает токсичность сообщения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов и пропусков в исходных данных нет. (т.к. в столбце Unnamed: 0 ни одно значение не повторяется, стоит проверить дубликаты после его удаления)  \n",
    "Текст комментариев содержит слова в верхнем и нижнем регистре, слэнг, сокращения слов, символы и коды. Это нужно будет обработать.  \n",
    "10% комментариев помечены токсичными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишим функцию, которая приведет все символы к нижнему регистру, заменит сокращения и слэнг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text) \n",
    "    text = re.sub(r\"it´s\", \"it is\", text)    \n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "    text = re.sub(r\"'d\", \" would\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)    \n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)       \n",
    "    text = re.sub(r\"'s\", \" \", text)\n",
    "    text = re.sub(r\"'n'\", \" and \", text)\n",
    "    text = re.sub(r\"n'\", \"ing\", text)\n",
    "    text = re.sub(r\"y'all\", \"you all\", text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [00:02<00:00, 60522.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "#df = df[:10]\n",
    "df['text'] = df['text'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем данные с помощью NLP библиотеки SpaСy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [12:35<00:00, 210.83it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "def spacy(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['lemma'] = df['text'].progress_apply(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my username hardcore metallica fan were reverted? they were not vandalisms, just closure on some gas after i voted at new york dolls fac. and please do not remove the template from the talk page since i am retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation \\n why the edit make under my username hardcore metallica fan be revert ? they be not vandalism , just closure on some gas after I vote at new york dolls fac . and please do not remove the template from the talk page since I be retire now.89.205.38.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i am seemingly stuck with. thanks.  (talk) 21:51, january 11, 2016 (utc)</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww ! he match this background colour I be seemingly stuck with . thank .   ( talk ) 21:51 , january 11 , 2016 ( utc )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. he seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , I be really not try to edit war . it be just that this guy be constantly remove relevant information and talk to I through edit instead of my talk page . he seem to care more about the formatting than the actual info .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni ca not make any real suggestions on improvement - i wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -i think the references may need tidying so that they are all in the exact same format ie date format etc. i can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nthere appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg wikipedia:good_article_nominations#transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>\" \\n more \\n I can not make any real suggestion on improvement - I wonder if the section statistic should be later on , or a subsection of \" \" type of accident \" \"   -i think the reference may need tidying so that they be all in the exact same format ie date format etc . I can do that later on , if no - one else do first - if you have any preference for format style on reference or want to do it yourself please let I know . \\n\\n there appear to be a backlog on article for review so I guess there may be a delay until a reviewer turn up . it be list in the relevant form eg wikipedia : good_article_nominations#transport   \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember what page that is on?</td>\n",
       "      <td>0</td>\n",
       "      <td>you , sir , be my hero . any chance you remember what page that be on ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                          explanation\\nwhy the edits made under my username hardcore metallica fan were reverted? they were not vandalisms, just closure on some gas after i voted at new york dolls fac. and please do not remove the template from the talk page since i am retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     d'aww! he matches this background colour i am seemingly stuck with. thanks.  (talk) 21:51, january 11, 2016 (utc)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           hey man, i am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. he seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nmore\\ni ca not make any real suggestions on improvement - i wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -i think the references may need tidying so that they are all in the exact same format ie date format etc. i can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nthere appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg wikipedia:good_article_nominations#transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  you, sir, are my hero. any chance you remember what page that is on?   \n",
       "\n",
       "   toxic  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  lemma  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                               explanation \\n why the edit make under my username hardcore metallica fan be revert ? they be not vandalism , just closure on some gas after I vote at new york dolls fac . and please do not remove the template from the talk page since I be retire now.89.205.38.27  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              d'aww ! he match this background colour I be seemingly stuck with . thank .   ( talk ) 21:51 , january 11 , 2016 ( utc )  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                  hey man , I be really not try to edit war . it be just that this guy be constantly remove relevant information and talk to I through edit instead of my talk page . he seem to care more about the formatting than the actual info .  \n",
       "3  \" \\n more \\n I can not make any real suggestion on improvement - I wonder if the section statistic should be later on , or a subsection of \" \" type of accident \" \"   -i think the reference may need tidying so that they be all in the exact same format ie date format etc . I can do that later on , if no - one else do first - if you have any preference for format style on reference or want to do it yourself please let I know . \\n\\n there appear to be a backlog on article for review so I guess there may be a delay until a reviewer turn up . it be list in the relevant form eg wikipedia : good_article_nominations#transport   \"  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               you , sir , be my hero . any chance you remember what page that be on ?  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим данные до обработки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159211 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   toxic   159211 non-null  int64 \n",
      " 1   lemma   159211 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['text'], axis=1)\n",
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим признаки разобьем на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('toxic', axis=1)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    test_size = 0.25,\n",
    "    random_state = RS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119408, 1)\n",
      "(119408,)\n",
      "(39803, 1)\n",
      "(39803,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим распределение целевого признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898481\n",
      "1    0.101519\n",
      "Name: toxic, dtype: float64\n",
      "0    0.898533\n",
      "1    0.101467\n",
      "Name: toxic, dtype: float64\n",
      "0    0.898324\n",
      "1    0.101676\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['toxic'].value_counts(normalize=True))\n",
    "print(target_train.value_counts(normalize=True))\n",
    "print(target_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим стоп слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lysergide\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе предобработки данных мы:\n",
    "   - привели текст к нижнему регистру и преобразовали сокращения в тексте.  \n",
    "   - обработали текст с помощью NLP библиотеки SpaCy.  \n",
    "   - подготовили признаки и разбили данные на выборки для обучения моделей.  \n",
    "   - добавили стоп слова.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы рассмотрим 3 способа векторизации:  \n",
    "1). CountVectorizer - преобразовывает текст в векторы количества слов.  \n",
    "2). TfidfVectorizer - преобразовывает текст в частотные векторы слова.  \n",
    "3). HashingVectorizer - преобразовывает текст в уникальные целые числа.  \n",
    "  \n",
    "На примере 2-х моделей: Logistic Regression с взвешиванием классов и LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим таблицу с результатами точности моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, vectorizer, model_var, f1_train]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = pd.DataFrame(columns =   ['model_name', 'vectorizer', 'model_var', 'f1_train'])\n",
    "display(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишим функцию, которая будет добавлять результат в таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_result (model_name, vectorizer, model_var, f1_train, models):\n",
    "    result = [model_name, vectorizer, model_var, f1_train]\n",
    "    rows = [pd.Series(result, index = models.columns)]\n",
    "    models = models.append(rows, ignore_index = True)\n",
    "    return(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression с взвешиванием классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование текста с помощью CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lysergide\\AppData\\Local\\Temp\\ipykernel_7732\\1690345207.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models = models.append(rows, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name       vectorizer  \\\n",
       "0  Logistic Regression  CountVectorizer   \n",
       "\n",
       "                                        model_var  f1_train  \n",
       "0  {'clf__C': 2, 'clf__class_weight': 'balanced'}     0.783  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "vectorizer = \"CountVectorizer\"\n",
    "\n",
    "model_lr_count = Pipeline(\n",
    "    [\n",
    "        ('count',\n",
    "         CountVectorizer(\n",
    "             ngram_range = (1,3),\n",
    "             min_df = 2,\n",
    "             max_df = 0.9,\n",
    "             analyzer = 'word',\n",
    "             lowercase = True,\n",
    "             binary = True,\n",
    "             stop_words = stopwords,\n",
    "             dtype = np.float32\n",
    "         )\n",
    "        ),\n",
    "        ('clf',\n",
    "         LogisticRegression(\n",
    "             random_state = RS,\n",
    "             max_iter = 2500\n",
    "         )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_lr_count = {\n",
    "#    'clf__C': range(1,31,1),\n",
    "    'clf__C': [2],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_lr_count = GridSearchCV(\n",
    "    estimator = model_lr_count,\n",
    "    param_grid = params_lr_count,\n",
    "    scoring = 'f1',\n",
    "    cv = KFOLD,\n",
    "    n_jobs = -1,\n",
    "    refit = False\n",
    ")\n",
    "\n",
    "grid_lr_count.fit(features_train['lemma'], target_train)\n",
    "\n",
    "model_var = grid_lr_count.best_params_\n",
    "f1_train = round(grid_lr_count.best_score_, 3)\n",
    "\n",
    "models = models_result(model_name, vectorizer, model_var, f1_train, models)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование текста с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lysergide\\AppData\\Local\\Temp\\ipykernel_7732\\1690345207.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models = models.append(rows, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name       vectorizer  \\\n",
       "0  Logistic Regression  CountVectorizer   \n",
       "1  Logistic Regression  TfidfVectorizer   \n",
       "\n",
       "                                         model_var  f1_train  \n",
       "0   {'clf__C': 2, 'clf__class_weight': 'balanced'}     0.783  \n",
       "1  {'clf__C': 15, 'clf__class_weight': 'balanced'}     0.783  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "vectorizer = \"TfidfVectorizer\"\n",
    "\n",
    "model_lr_tfidf = Pipeline(\n",
    "    [\n",
    "        ('tfidf',\n",
    "         TfidfVectorizer(\n",
    "             ngram_range = (1,3),\n",
    "             min_df = 2,\n",
    "             max_df = 0.9,\n",
    "             use_idf = 1,\n",
    "             smooth_idf = 1,\n",
    "             sublinear_tf = 1,\n",
    "             stop_words = stopwords\n",
    "         )\n",
    "        ),\n",
    "        ('clf',\n",
    "         LogisticRegression(\n",
    "             random_state = RS,\n",
    "             max_iter = 2500\n",
    "         )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_lr_tfidf = {\n",
    "#    'clf__C': range(1,31,1),\n",
    "    'clf__C': [15],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_lr_tfidf = GridSearchCV(\n",
    "    estimator = model_lr_tfidf,\n",
    "    param_grid = params_lr_tfidf,\n",
    "    scoring = 'f1',\n",
    "    cv = KFOLD,\n",
    "    n_jobs = -1,\n",
    "    refit = False\n",
    ")\n",
    "\n",
    "grid_lr_tfidf.fit(features_train['lemma'], target_train)\n",
    "\n",
    "model_var = grid_lr_tfidf.best_params_\n",
    "f1_train = round(grid_lr_tfidf.best_score_, 3)\n",
    "\n",
    "models = models_result(model_name, vectorizer, model_var, f1_train, models)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование текста с помощью HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lysergide\\AppData\\Local\\Temp\\ipykernel_7732\\1690345207.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models = models.append(rows, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__C': 13, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name         vectorizer  \\\n",
       "0  Logistic Regression    CountVectorizer   \n",
       "1  Logistic Regression    TfidfVectorizer   \n",
       "2  Logistic Regression  HashingVectorizer   \n",
       "\n",
       "                                         model_var  f1_train  \n",
       "0   {'clf__C': 2, 'clf__class_weight': 'balanced'}     0.783  \n",
       "1  {'clf__C': 15, 'clf__class_weight': 'balanced'}     0.783  \n",
       "2  {'clf__C': 13, 'clf__class_weight': 'balanced'}     0.780  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "vectorizer = \"HashingVectorizer\"\n",
    "\n",
    "model_lr_hashing = Pipeline(\n",
    "    [\n",
    "        ('hashing',\n",
    "         HashingVectorizer(\n",
    "             ngram_range = (1,3),\n",
    "             analyzer = 'word',\n",
    "             lowercase = True,\n",
    "             binary = True,\n",
    "             stop_words = stopwords,\n",
    "             dtype = np.float32\n",
    "         )\n",
    "        ),\n",
    "        ('clf',\n",
    "         LogisticRegression(\n",
    "             random_state = RS,\n",
    "             max_iter = 2500\n",
    "         )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_lr_hashing = {\n",
    "#    'clf__C': range(1,31,1),\n",
    "    'clf__C': [13],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_lr_hashing = GridSearchCV(\n",
    "    estimator = model_lr_hashing,\n",
    "    param_grid = params_lr_hashing,\n",
    "    scoring = 'f1',\n",
    "    cv = KFOLD,\n",
    "    n_jobs = -1,\n",
    "    refit = False\n",
    ")\n",
    "\n",
    "grid_lr_hashing.fit(features_train['lemma'], target_train)\n",
    "\n",
    "model_var = grid_lr_hashing.best_params_\n",
    "f1_train = round(grid_lr_hashing.best_score_, 3)\n",
    "\n",
    "models = models_result(model_name, vectorizer, model_var, f1_train, models)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование текста с помощью CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lysergide\\AppData\\Local\\Temp\\ipykernel_7732\\1690345207.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models = models.append(rows, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__C': 13, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name         vectorizer  \\\n",
       "0  Logistic Regression    CountVectorizer   \n",
       "1  Logistic Regression    TfidfVectorizer   \n",
       "2  Logistic Regression  HashingVectorizer   \n",
       "3             LightGBM    CountVectorizer   \n",
       "\n",
       "                                                                     model_var  \\\n",
       "0                               {'clf__C': 2, 'clf__class_weight': 'balanced'}   \n",
       "1                              {'clf__C': 15, 'clf__class_weight': 'balanced'}   \n",
       "2                              {'clf__C': 13, 'clf__class_weight': 'balanced'}   \n",
       "3  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}   \n",
       "\n",
       "   f1_train  \n",
       "0     0.783  \n",
       "1     0.783  \n",
       "2     0.780  \n",
       "3     0.776  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"LightGBM\"\n",
    "vectorizer = \"CountVectorizer\"\n",
    "\n",
    "model_lgbm_count = Pipeline(\n",
    "    [\n",
    "        ('count',\n",
    "         CountVectorizer(\n",
    "             ngram_range = (1,3),\n",
    "             min_df = 2,\n",
    "             max_df = 0.9,\n",
    "             analyzer = 'word',\n",
    "             lowercase = True,\n",
    "             binary = True,\n",
    "             stop_words = stopwords,\n",
    "             dtype=np.float32\n",
    "         )\n",
    "        ),\n",
    "        ('clf', LGBMClassifier(random_state=RS, max_iter = 2500)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_lgbm_count = {\n",
    "  'clf__n_estimators': [100],\n",
    "  'clf__learning_rate': [0.1],\n",
    "  'clf__max_depth': [-1]}\n",
    "\n",
    "grid_lgbm_count = GridSearchCV(\n",
    "    estimator=model_lgbm_count,\n",
    "    param_grid=params_lgbm_count,\n",
    "    cv=KFOLD,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    refit=False\n",
    ")\n",
    "grid_lgbm_count.fit(features_train['lemma'], target_train)\n",
    "\n",
    "model_var = grid_lgbm_count.best_params_\n",
    "f1_train = round(grid_lgbm_count.best_score_, 3)\n",
    "\n",
    "models = models_result(model_name, vectorizer, model_var, f1_train, models)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование текста с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lysergide\\AppData\\Local\\Temp\\ipykernel_7732\\1690345207.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models = models.append(rows, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__C': 13, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name         vectorizer  \\\n",
       "0  Logistic Regression    CountVectorizer   \n",
       "1  Logistic Regression    TfidfVectorizer   \n",
       "2  Logistic Regression  HashingVectorizer   \n",
       "3             LightGBM    CountVectorizer   \n",
       "4             LightGBM    TfidfVectorizer   \n",
       "\n",
       "                                                                     model_var  \\\n",
       "0                               {'clf__C': 2, 'clf__class_weight': 'balanced'}   \n",
       "1                              {'clf__C': 15, 'clf__class_weight': 'balanced'}   \n",
       "2                              {'clf__C': 13, 'clf__class_weight': 'balanced'}   \n",
       "3  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}   \n",
       "4  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "\n",
       "   f1_train  \n",
       "0     0.783  \n",
       "1     0.783  \n",
       "2     0.780  \n",
       "3     0.776  \n",
       "4     0.768  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"LightGBM\"\n",
    "vectorizer = \"TfidfVectorizer\"\n",
    "\n",
    "model_lgbm_tfidf = Pipeline(\n",
    "    [\n",
    "        ('tfidf',\n",
    "         TfidfVectorizer(\n",
    "             ngram_range = (1,3),\n",
    "             min_df = 2,\n",
    "             max_df = 0.9,\n",
    "             use_idf = 1,\n",
    "             smooth_idf = 1,\n",
    "             sublinear_tf = 1,\n",
    "             stop_words = stopwords\n",
    "         )\n",
    "        ),\n",
    "        ('clf', LGBMClassifier(random_state=RS, max_iter = 2500)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_lgbm_tfidf = {\n",
    "  'clf__n_estimators': [500],\n",
    "  'clf__learning_rate': [0.1],\n",
    "  'clf__max_depth': [-1]}\n",
    "\n",
    "grid_lgbm_tfidf = GridSearchCV(\n",
    "    estimator=model_lgbm_tfidf,\n",
    "    param_grid=params_lgbm_tfidf,\n",
    "    cv=KFOLD,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    refit=False\n",
    ")\n",
    "grid_lgbm_tfidf.fit(features_train['lemma'], target_train)\n",
    "\n",
    "model_var = grid_lgbm_tfidf.best_params_\n",
    "f1_train = round(grid_lgbm_tfidf.best_score_, 3)\n",
    "\n",
    "models = models_result(model_name, vectorizer, model_var, f1_train, models)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование текста с помощью HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lysergide\\AppData\\Local\\Temp\\ipykernel_7732\\1690345207.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  models = models.append(rows, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__C': 13, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name         vectorizer  \\\n",
       "0  Logistic Regression    CountVectorizer   \n",
       "1  Logistic Regression    TfidfVectorizer   \n",
       "2  Logistic Regression  HashingVectorizer   \n",
       "3             LightGBM    CountVectorizer   \n",
       "4             LightGBM    TfidfVectorizer   \n",
       "5             LightGBM  HashingVectorizer   \n",
       "\n",
       "                                                                     model_var  \\\n",
       "0                               {'clf__C': 2, 'clf__class_weight': 'balanced'}   \n",
       "1                              {'clf__C': 15, 'clf__class_weight': 'balanced'}   \n",
       "2                              {'clf__C': 13, 'clf__class_weight': 'balanced'}   \n",
       "3  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}   \n",
       "4  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "5  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "\n",
       "   f1_train  \n",
       "0     0.783  \n",
       "1     0.783  \n",
       "2     0.780  \n",
       "3     0.776  \n",
       "4     0.768  \n",
       "5     0.768  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"LightGBM\"\n",
    "vectorizer = \"HashingVectorizer\"\n",
    "\n",
    "model_lgbm_hashing = Pipeline(\n",
    "    [\n",
    "        ('hashing',\n",
    "         HashingVectorizer(\n",
    "             ngram_range = (1,3),\n",
    "             analyzer = 'word',\n",
    "             lowercase = True,\n",
    "             binary = True,\n",
    "             stop_words = stopwords,\n",
    "             dtype = np.float32\n",
    "         )\n",
    "        ),\n",
    "        ('clf', LGBMClassifier(random_state=RS, max_iter = 2500)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_lgbm_hashing = {\n",
    "  'clf__n_estimators': [500],\n",
    "  'clf__learning_rate': [0.1],\n",
    "  'clf__max_depth': [-1]}\n",
    "\n",
    "grid_lgbm_hashing = GridSearchCV(\n",
    "    estimator=model_lgbm_hashing,\n",
    "    param_grid=params_lgbm_hashing,\n",
    "    cv=KFOLD,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    refit=False\n",
    ")\n",
    "grid_lgbm_hashing.fit(features_train['lemma'], target_train)\n",
    "\n",
    "model_var = grid_lgbm_hashing.best_params_\n",
    "f1_train = round(grid_lgbm_hashing.best_score_, 3)\n",
    "\n",
    "models = models_result(model_name, vectorizer, model_var, f1_train, models)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили 2 модели с использованием 3-х разных векторизаций для каждой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__C': 13, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name         vectorizer  \\\n",
       "0  Logistic Regression    CountVectorizer   \n",
       "1  Logistic Regression    TfidfVectorizer   \n",
       "2  Logistic Regression  HashingVectorizer   \n",
       "3             LightGBM    CountVectorizer   \n",
       "4             LightGBM    TfidfVectorizer   \n",
       "5             LightGBM  HashingVectorizer   \n",
       "\n",
       "                                                                     model_var  \\\n",
       "0                               {'clf__C': 2, 'clf__class_weight': 'balanced'}   \n",
       "1                              {'clf__C': 15, 'clf__class_weight': 'balanced'}   \n",
       "2                              {'clf__C': 13, 'clf__class_weight': 'balanced'}   \n",
       "3  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}   \n",
       "4  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "5  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "\n",
       "   f1_train  \n",
       "0     0.783  \n",
       "1     0.783  \n",
       "2     0.780  \n",
       "3     0.776  \n",
       "4     0.768  \n",
       "5     0.768  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values('f1_train', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение на тренировочной выборке показала модель: Logistic Regression с взвешиванием классов. Исследование показало, что выбор способа векторизации практически не влияет на точность модели, поэтому тестировать придется все 3 модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишим функцию для тестирования моделей на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test (model_id, model_name, vectorizer):\n",
    "#    test_predict = model_id.estimator.set_params(**model_id.best_params_).predict(features_test['lemma'])\n",
    "    test_predict = model_id.fit(features_train['lemma'], target_train).predict(features_test['lemma'])\n",
    "    f1_test = f1_score(target_test, test_predict)\n",
    "    return (model_name, vectorizer, round(f1_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Logistic Regression', 'TfidfVectorizer', 0.707)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(model_lr_tfidf, \"Logistic Regression\", \"TfidfVectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Logistic Regression', 'CountVectorizer', 0.778)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(model_lr_count, \"Logistic Regression\", \"CountVectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Logistic Regression', 'HashingVectorizer', 0.665)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(model_lr_hashing, \"Logistic Regression\", \"HashingVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую точность метрики качества F1 (0.778) на тестовой выборке показала модель: Logistic Regression с векторизатором CountVectorizer. Это удовлетворяет условию задачи. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный датасет состоит из 159292 строк и 3-х столбцов:\n",
    " - Unnamed: 0 - отражает порядковый номер комментария, для исследования не несет никакой ценности, мы его удалили.\n",
    " - text - это сам комментарий, сожержит текстовое сообщение, с которым нам предстоит работать.\n",
    " - toxic - это наш целевой признак, он отражает токсичность сообщения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в исходных данных нет. Дубликаты были удалены.   \n",
    "Текст комментариев содержит слова в верхнем и нижнем регистре, слэнг, сокращения слов, символы и коды. Это нужно будет обработать.  \n",
    "10% комментариев помечены токсичными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе предобработки данных мы:\n",
    "   - привели текст к нижнему регистру и преобразовали сокращения в тексте.  \n",
    "   - перевели текст в формат Unicode.  \n",
    "   - обработали текст с помощью NLP библиотеки SpaCy.  \n",
    "   - подготовили признаки и разбили данные на выборки для обучения моделей.  \n",
    "   - добавили стоп слова.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили 2 модели с использованием 3-х разных векторизаций для каждой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model_var</th>\n",
       "      <th>f1_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__C': 2, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__C': 15, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__C': 13, 'clf__class_weight': 'balanced'}</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HashingVectorizer</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name         vectorizer  \\\n",
       "0  Logistic Regression    CountVectorizer   \n",
       "1  Logistic Regression    TfidfVectorizer   \n",
       "2  Logistic Regression  HashingVectorizer   \n",
       "3             LightGBM    CountVectorizer   \n",
       "4             LightGBM    TfidfVectorizer   \n",
       "5             LightGBM  HashingVectorizer   \n",
       "\n",
       "                                                                     model_var  \\\n",
       "0                               {'clf__C': 2, 'clf__class_weight': 'balanced'}   \n",
       "1                              {'clf__C': 15, 'clf__class_weight': 'balanced'}   \n",
       "2                              {'clf__C': 13, 'clf__class_weight': 'balanced'}   \n",
       "3  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 100}   \n",
       "4  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "5  {'clf__learning_rate': 0.1, 'clf__max_depth': -1, 'clf__n_estimators': 500}   \n",
       "\n",
       "   f1_train  \n",
       "0     0.783  \n",
       "1     0.783  \n",
       "2     0.780  \n",
       "3     0.776  \n",
       "4     0.768  \n",
       "5     0.768  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values('f1_train', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение на тренировочной выборке показала модель: Logistic Regression с взвешиванием классов. Исследование показало, что выбор способа векторизации практически не влияет на точность модели, поэтому тестировать придется все 3 модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую точность метрики качества F1 (0.778) на тестовой выборке показала модель: Logistic Regression с векторизатором CountVectorizer. Это удовлетворяет условию задачи. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 46,
    "start_time": "2023-01-31T14:55:32.543Z"
   },
   {
    "duration": 17683,
    "start_time": "2023-01-31T19:58:55.245Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-31T19:59:12.931Z"
   },
   {
    "duration": 3713,
    "start_time": "2023-01-31T19:59:12.936Z"
   },
   {
    "duration": 27,
    "start_time": "2023-01-31T19:59:16.651Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-31T19:59:16.679Z"
   },
   {
    "duration": 233,
    "start_time": "2023-01-31T19:59:16.701Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-31T19:59:16.936Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-31T19:59:16.949Z"
   },
   {
    "duration": 27,
    "start_time": "2023-01-31T19:59:16.974Z"
   },
   {
    "duration": 824,
    "start_time": "2023-01-31T19:59:17.002Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-31T19:59:17.828Z"
   },
   {
    "duration": 35,
    "start_time": "2023-01-31T19:59:17.834Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-31T19:59:17.871Z"
   },
   {
    "duration": 44,
    "start_time": "2023-01-31T19:59:17.884Z"
   },
   {
    "duration": 927,
    "start_time": "2023-01-31T19:59:17.930Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-31T19:59:18.859Z"
   },
   {
    "duration": 76,
    "start_time": "2023-02-01T18:49:41.236Z"
   },
   {
    "duration": 89,
    "start_time": "2023-02-01T18:58:00.685Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "442px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
